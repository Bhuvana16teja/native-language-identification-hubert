# -*- coding: utf-8 -*-
"""NLI_FINAL_NOTEBOOK.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LfHdXBp0V02xUPFDMLSW892N3fFemMoC
"""

# ================================================================
#  SINGLE-CELL NOTEBOOK
#  HuBERT Layer-6 Accent + Cuisine + Age + Phrase Type Model
#  With Shape-Fixing, Pitch, Duration, and Gradio UI
# ================================================================

# ---------- STEP 1: Mount Drive ----------
from google.colab import drive
drive.mount('/content/drive')

# ----------- File IDs (Added) ----------
L6_FILE_ID = "19wbB3Cpji1M2CFcnq90Q6i1VFUYNETSi"
L9_12_FILE_ID = "1fExac4uFRnFXrSVF_M7UIKe4JNDQSnKd"

PROJECT_DIR = "/content/drive/MyDrive/accent_project"
CACHE = f"{PROJECT_DIR}/L6_features_cache.npz"

# ---------- DOWNLOAD FILES AUTOMATICALLY ----------
import gdown, os

print("â¬‡ï¸ Checking & Downloading L6 file...")
if not os.path.exists(CACHE):
    # ensure target dir exists
    os.makedirs(os.path.dirname(CACHE), exist_ok=True)
    gdown.download(f"https://drive.google.com/uc?id={L6_FILE_ID}", CACHE, quiet=False)
else:
    print("âœ”ï¸ L6 cache already exists")

L9_12_PATH = f"{PROJECT_DIR}/L9-12_features_cache.npz"
print("â¬‡ï¸ Checking & Downloading L9â€“12 file...")
if not os.path.exists(L9_12_PATH):
    os.makedirs(os.path.dirname(L9_12_PATH), exist_ok=True)
    gdown.download(f"https://drive.google.com/uc?id={L9_12_FILE_ID}", L9_12_PATH, quiet=False)
else:
    print("âœ”ï¸ L9-12 cache already exists")


# ---------- STEP 2: Install Dependencies ----------
!pip install librosa==0.10.1 torchaudio transformers pandas numpy scikit-learn soundfile gradio tqdm --quiet

import numpy as np
import librosa
import torch
from transformers import Wav2Vec2FeatureExtractor, HubertModel
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import gradio as gr

print("ğŸ”¥ All dependencies ready.")

# ---------- STEP 3: Load Cached Features ----------
print("ğŸ“ Loading cached embeddings...")

cache = np.load(CACHE, allow_pickle=True)
features = list(cache["features"])
labels = list(cache["labels"])
pitch_list = list(cache["pitch"])
duration_list = list(cache["duration"])

EXPECTED_DIM = len(features[0])  # IMPORTANT: embedding+pitch+duration size

print(f"âœ… Loaded {len(features)} samples | Expected Feature Size = {EXPECTED_DIM}")


# ---------- STEP 4: Fix Feature Shape ----------
def normalize_feature(vec, target_dim=EXPECTED_DIM):
    """Ensures prediction feature matches training dimension."""
    if len(vec) > target_dim:
        return vec[:target_dim]
    elif len(vec) < target_dim:
        return np.pad(vec, (0, target_dim - len(vec)))
    return vec


# ---------- STEP 5: Train Accent Model ----------
print("ğŸ¤ Training Accent Classifier...")

X = np.array([normalize_feature(f) for f in features])
y = np.array(labels)

le = LabelEncoder()
y_enc = le.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, stratify=y_enc, random_state=42)

scaler = StandardScaler().fit(X_train)

accent_clf = MLPClassifier(hidden_layer_sizes=(512, 256), max_iter=100)
accent_clf.fit(scaler.transform(X_train), y_train)

print("\nğŸ“Œ Accent Model Report:")
print(classification_report(y_test, accent_clf.predict(scaler.transform(X_test)), target_names=le.classes_))


# ---------- STEP 6: Age Model (Pitch-Based) ----------
print("\nğŸ‘¶ğŸ§‘ Training Age Model...")

age_labels = ["Child" if p > 250 else "Adult" for p in pitch_list]

age_le = LabelEncoder()
age_enc = age_le.fit_transform(age_labels)

age_clf = MLPClassifier(hidden_layer_sizes=(32, 16), max_iter=50)
age_clf.fit(np.array(pitch_list).reshape(-1,1), age_enc)

print("âœ… Age classifier ready.")


# ---------- STEP 7: Rule-Based Phrase Type ----------
print("ğŸ—£ï¸ Phrase classifier: Word < 1.2s else Sentence")


# ---------- STEP 8: HuBERT for New Audio ----------
device = "cuda" if torch.cuda.is_available() else "cpu"

feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained("facebook/hubert-base-ls960")
hubert = HubertModel.from_pretrained("facebook/hubert-base-ls960", output_hidden_states=True).to(device)
hubert.eval()

def hubert_layer6(audio, sr=16000):
    inp = feature_extractor(audio, sampling_rate=sr, return_tensors="pt")
    inp = {k: v.to(device) for k, v in inp.items()}

    with torch.no_grad():
        out = hubert(**inp)

    emb = out.hidden_states[6].mean(dim=1).cpu().numpy().flatten()
    return emb


# ---------- STEP 9: Pitch & Duration Functions ----------
def extract_pitch(audio):
    f0, _, _ = librosa.pyin(audio, fmin=80, fmax=400, frame_length=1024)
    valid = f0[~np.isnan(f0)]
    return float(np.mean(valid)) if len(valid) > 0 else 0.0

def extract_duration(audio, sr=16000):
    return len(audio) / sr


# ---------- STEP 10: Cuisine Mapping ----------
cuisine_map = {
    "tamil": "ğŸ› Idli, Dosa, Pongal, Sambar",
    "kerala": "ğŸ¥¥ Appam, Puttu, Kerala Sadhya",
    "karnataka": "ğŸ² Bisi Bele Bath, Ragi Mudde",
    "jharkhand": "ğŸ”¥ Litti Chokha, Pittha",
    "gujarat": "ğŸ¥— Dhokla, Thepla, Undhiyu",
    "andhra_pradesh": "ğŸŒ¶ï¸ Biryani, Gongura Pachadi"
}


# ---------- STEP 11: Prediction Function ----------
def predict_all(audio_file):
    try:
        audio, sr = librosa.load(audio_file, sr=16000)

        pitch = extract_pitch(audio)
        duration = extract_duration(audio)
        hub = hubert_layer6(audio)

        full = normalize_feature(np.concatenate([hub, [pitch, duration]])).reshape(1, -1)

        # Accent
        acc_idx = accent_clf.predict(scaler.transform(full))[0]
        accent = le.inverse_transform([acc_idx])[0]

        cuisine = cuisine_map.get(accent.lower(), "ğŸ´ No cuisine match found")

        age_pred = age_le.inverse_transform(age_clf.predict([[pitch]]))[0]

        phrase_type = "Word" if duration < 1.2 else "Sentence"

        return accent, cuisine, age_pred, phrase_type, round(pitch, 2), round(duration, 2)

    except Exception as e:
        print("âŒ ERROR:", e)
        return "Error", "Error", "Error", "Error", "Error", "Error"


# ---------- STEP 12: Gradio UI ----------
demo = gr.Interface(
    fn=predict_all,
    inputs=gr.Audio(type="filepath", label="ğŸ¤ Upload Voice Sample"),
    outputs=[
        gr.Textbox(label="Predicted Accent"),
        gr.Textbox(label="Suggested Cuisine"),
        gr.Textbox(label="Age Group"),
        gr.Textbox(label="Phrase Type"),
        gr.Number(label="Pitch (Hz)"),
        gr.Number(label="Duration (sec)")
    ],
    title="ğŸ‡®ğŸ‡³ Accent + Food Recommendation AI ğŸ²",
    description="Upload a short voice sample (1â€“4 seconds)."
)

demo.launch(share=False)

# ---------- STEP 13: Layer-Wise Evaluation ----------

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import f1_score, confusion_matrix, accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import LabelEncoder

# ---------- FILE CHECK + DOWNLOAD ----------
from google.colab import drive
drive.mount('/content/drive')

FILE_ID = "1fExac4uFRnFXrSVF_M7UIKe4JNDQSnKd"   # <<<<<< UPDATED FILE ID
DEST_PATH = f"{PROJECT_DIR}/L9-12_features_cache.npz"

import os

# If file doesn't exist, download
if not os.path.exists(DEST_PATH):
    print("â¬‡ï¸ Downloading L9â€“12 embeddings file...")
    !gdown --id {FILE_ID} -O {DEST_PATH}
else:
    print("âœ”ï¸ File already exists.")

# ---------- Load L9â€“12 Cache ----------
print("\nğŸ“ Loading L9â€“12 Embeddings...")
l9_12_cache = np.load(DEST_PATH, allow_pickle=True)

layers = {
    6: X,  # Layer 6 features (already loaded earlier)
    9: l9_12_cache['features9'],
    10: l9_12_cache['features10'],
    11: l9_12_cache['features11'],
    12: l9_12_cache['features12']
}

# ---------- Labels ----------
labels_all = np.array(l9_12_cache['labels'])
le_layers = LabelEncoder()
y_all_enc = le_layers.fit_transform(labels_all)

layer_results = {}

for l_num, feats in layers.items():

    feats_norm = np.array([normalize_feature(f) for f in feats])

    X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(
        feats_norm, y_all_enc, test_size=0.2, stratify=y_all_enc, random_state=42
    )

    scaler_l = StandardScaler().fit(X_train_l)

    if l_num == 6:
        clf_l = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=100, random_state=42)
    else:
        clf_l = MLPClassifier(hidden_layer_sizes=(512, 256), max_iter=100, random_state=42)

    clf_l.fit(scaler_l.transform(X_train_l), y_train_l)
    y_pred_l = clf_l.predict(scaler_l.transform(X_test_l))

    acc = accuracy_score(y_test_l, y_pred_l)
    f1 = f1_score(y_test_l, y_pred_l, average='weighted')

    layer_results[l_num] = {'accuracy': acc, 'f1': f1}

    print(f"\nğŸ“Š Layer {l_num} | Accuracy: {acc:.4f} | F1-score: {f1:.4f}")

    if l_num == 6:
        cm = confusion_matrix(y_test_l, y_pred_l)
        plt.figure(figsize=(8,6))
        sns.heatmap(cm, annot=True, fmt='d', xticklabels=le_layers.classes_, yticklabels=le_layers.classes_, cmap="Blues")
        plt.title("Confusion Matrix - Layer 6")
        plt.xlabel("Predicted")
        plt.ylabel("True")
        plt.show()

# ---------- Summary ----------
print("\nâœ… Layer-Wise Summary:")
for l in sorted(layer_results.keys()):
    print(f"Layer {l}: Accuracy = {layer_results[l]['accuracy']:.2f}, F1-score = {layer_results[l]['f1']:.2f}")